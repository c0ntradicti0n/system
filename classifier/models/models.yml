defaults: &defaults
  embedding_dim: 1024
  batch_size: 2000
  n_epochs: 10000
  stop_f1_score: 0.93
  weight_decay: 0.001
  batches_per_epoch: 1
  embedding_model: BAAI/bge-large-en-v1.5

siamese: &siamese
  <<: *defaults
  model: siamese

classifier: &classifier
  <<: *defaults
  model: ntuple
  lr: 0.00003


models:
  thesis_antithesis_synthesis:
    <<: *classifier
    n_samples: 3
    n_classes: 4
    batch_size: 1000
    from_file: classifier.data.thesis_antithesis_synthesis
    batches_per_epoch: 17
    classes:
      - valid
      - from_file
    probs:
      - 0.95
      - 0.05
    relations:
      - syn_1
      - syn_2
  score_hierarchy:
    <<: *siamese
    samples: classifier.data.hierarchy
    inverse: true
    relations:
      - hie
  hierarchy:
    <<: *classifier
    n_classes: 3
    n_samples: 2
    batches_per_epoch: 17
    batch_size: 1000
    classes:
      - valid_hie_wordnet
    probs:
      - 1
    lr: 0.003
    relations:
      - hie

  opposites:
    <<: *siamese
    samples: classifier.data.opposites
    inverse: true
    batch_size: 1000
    n_samples: 2
    relations:
      - ant










